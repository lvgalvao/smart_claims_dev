{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task_002 - Criar Volumes no Schema 00_landing\n",
        "\n",
        "Este notebook cria volumes no schema `00_landing` para organizar diferentes tipos de dados do projeto Smart Claims.\n",
        "\n",
        "## Volumes a serem criados:\n",
        "- `claims` - Volume para dados e imagens de sinistros (CSV, imagens, metadata)\n",
        "- `sql_server` - Volume para dados extra√≠dos do SQL Server (CSV: claims, customers, policies)\n",
        "- `telematics` - Volume para dados de telemetria veicular (arquivos Parquet)\n",
        "- `training_imgs` - Volume para imagens de treinamento de modelos de Machine Learning (PNG)\n",
        "\n",
        "## O que s√£o Volumes no Unity Catalog?\n",
        "- **Volumes** s√£o containers de arquivos no Unity Catalog\n",
        "- Permitem armazenar arquivos n√£o estruturados ou semi-estruturados (CSV, JSON, Parquet, imagens, etc.)\n",
        "- Fornecem governan√ßa e controle de acesso granular\n",
        "- S√£o a alternativa moderna ao DBFS para armazenamento de arquivos\n",
        "- Permitem organizar dados por tipo ou origem antes do processamento\n",
        "\n",
        "## Nota sobre Upload\n",
        "Ap√≥s criar os volumes neste notebook, voc√™ pode fazer upload dos arquivos diretamente via **UI do Databricks**:\n",
        "1. Navegue at√©: Catalog ‚Üí smart_claims_dev ‚Üí 00_landing\n",
        "2. Clique no volume desejado\n",
        "3. Clique em **Upload** ou **Add files**\n",
        "4. Selecione os arquivos/pastas do seu sistema local\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 1: Garantir que o Cat√°logo e Schema existem\n",
        "\n",
        "Primeiro, vamos garantir que estamos usando o cat√°logo correto e que o schema 00_landing existe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Usar o cat√°logo smart_claims_dev\n",
        "USE CATALOG smart_claims_dev\n",
        "\n",
        "-- Verificar se o schema 00_landing existe\n",
        "SHOW SCHEMAS IN smart_claims_dev LIKE '00_landing'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 2: Criar Volumes no Schema 00_landing\n",
        "\n",
        "**COMANDO: CREATE VOLUME**\n",
        "\n",
        "O que faz:\n",
        "- Cria um volume dentro de um schema para armazenar arquivos\n",
        "- Volumes s√£o containers para arquivos n√£o estruturados ou semi-estruturados\n",
        "- Permitem controle de acesso granular atrav√©s do Unity Catalog\n",
        "- Suportam diferentes tipos de arquivo (CSV, JSON, Parquet, imagens PNG/JPG, etc.)\n",
        "\n",
        "**Documenta√ß√£o oficial:** [Unity Catalog - CREATE VOLUME](https://docs.databricks.com/en/connect/unity-catalog/create-volume.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Criar volume para dados de sinistros (claims)\n",
        "-- Este volume armazenar√°: imagens de sinistros (JPG), metadata (CSV) e outros arquivos relacionados\n",
        "CREATE VOLUME IF NOT EXISTS smart_claims_dev.00_landing.claims\n",
        "COMMENT 'Volume para armazenar dados e imagens de sinistros (CSV, imagens JPG, metadata)'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Criar volume para dados do SQL Server\n",
        "-- Este volume armazenar√°: claims.csv, customers.csv, policies.csv extra√≠dos do SQL Server\n",
        "CREATE VOLUME IF NOT EXISTS smart_claims_dev.00_landing.sql_server\n",
        "COMMENT 'Volume para armazenar dados extra√≠dos do SQL Server (CSV: claims, customers, policies)'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Criar volume para dados de telemetria (telematics)\n",
        "-- Este volume armazenar√°: arquivos Parquet com dados de telemetria veicular\n",
        "CREATE VOLUME IF NOT EXISTS smart_claims_dev.00_landing.telematics\n",
        "COMMENT 'Volume para armazenar dados de telemetria veicular (arquivos Parquet)'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Criar volume para imagens de treinamento (training_imgs)\n",
        "-- Este volume armazenar√°: imagens PNG classificadas para treinamento de modelos ML\n",
        "CREATE VOLUME IF NOT EXISTS smart_claims_dev.00_landing.training_imgs\n",
        "COMMENT 'Volume para armazenar imagens de treinamento de modelos de Machine Learning (PNG)'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 3: Verificar Volumes Criados\n",
        "\n",
        "Vamos verificar se todos os volumes foram criados com sucesso.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Listar todos os volumes no schema 00_landing\n",
        "SHOW VOLUMES IN smart_claims_dev.00_landing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 4: Como Fazer Upload dos Arquivos\n",
        "\n",
        "Ap√≥s criar os volumes, voc√™ pode fazer upload dos arquivos diretamente via **UI do Databricks**:\n",
        "\n",
        "### Passo a Passo:\n",
        "\n",
        "1. **Acesse o Unity Catalog:**\n",
        "   - No Databricks Workspace, clique em **Catalog** (no menu lateral)\n",
        "   - Expanda: **smart_claims_dev** ‚Üí **00_landing**\n",
        "\n",
        "2. **Para cada volume, fa√ßa upload dos arquivos:**\n",
        "   \n",
        "   **Volume `claims`:**\n",
        "   - Clique no volume `claims`\n",
        "   - Clique em **Upload** ou **Add files**\n",
        "   - Selecione a pasta `data/claims/` ou seus arquivos individuais\n",
        "   - Suba as imagens (JPG) e o arquivo de metadata (CSV)\n",
        "   \n",
        "   **Volume `sql_server`:**\n",
        "   - Clique no volume `sql_server`\n",
        "   - Clique em **Upload** ou **Add files**\n",
        "   - Selecione os arquivos da pasta `data/sql_server/`\n",
        "   - Suba: `claims.csv`, `customers.csv`, `policies.csv`\n",
        "   \n",
        "   **Volume `telematics`:**\n",
        "   - Clique no volume `telematics`\n",
        "   - Clique em **Upload** ou **Add files**\n",
        "   - Selecione todos os arquivos Parquet da pasta `data/telematics/`\n",
        "   \n",
        "   **Volume `training_imgs`:**\n",
        "   - Clique no volume `training_imgs`\n",
        "   - Clique em **Upload** ou **Add files**\n",
        "   - Selecione todas as imagens PNG da pasta `data/training_imgs/`\n",
        "\n",
        "### Estrutura Esperada ap√≥s Upload:\n",
        "\n",
        "```\n",
        "smart_claims_dev\n",
        "  ‚îî‚îÄ‚îÄ 00_landing\n",
        "      ‚îú‚îÄ‚îÄ claims/\n",
        "      ‚îÇ   ‚îú‚îÄ‚îÄ images/        (JPG files)\n",
        "      ‚îÇ   ‚îî‚îÄ‚îÄ metadata/      (CSV files)\n",
        "      ‚îú‚îÄ‚îÄ sql_server/\n",
        "      ‚îÇ   ‚îú‚îÄ‚îÄ claims.csv\n",
        "      ‚îÇ   ‚îú‚îÄ‚îÄ customers.csv\n",
        "      ‚îÇ   ‚îî‚îÄ‚îÄ policies.csv\n",
        "      ‚îú‚îÄ‚îÄ telematics/\n",
        "      ‚îÇ   ‚îî‚îÄ‚îÄ *.parquet      (m√∫ltiplos arquivos)\n",
        "      ‚îî‚îÄ‚îÄ training_imgs/\n",
        "          ‚îî‚îÄ‚îÄ *.png          (m√∫ltiplas imagens)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 5: Resumo dos Volumes Criados\n",
        "\n",
        "‚úÖ **4 volumes criados com sucesso no schema 00_landing:**\n",
        "\n",
        "1. **`claims`** - Dados e imagens de sinistros\n",
        "2. **`sql_server`** - Dados extra√≠dos do SQL Server (CSV)\n",
        "3. **`telematics`** - Dados de telemetria veicular (Parquet)\n",
        "4. **`training_imgs`** - Imagens para treinamento de ML (PNG)\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "Ap√≥s fazer upload dos arquivos via UI, voc√™ pode:\n",
        "\n",
        "- **Task_003**: Criar tabelas Delta na camada `01_bronze` a partir dos arquivos nos volumes\n",
        "- **Task_004**: Processar e transformar os dados (Bronze ‚Üí Silver ‚Üí Gold)\n",
        "- Usar os volumes para leitura direta em notebooks e pipelines\n",
        "\n",
        "### Documenta√ß√£o de Refer√™ncia\n",
        "\n",
        "- [Unity Catalog - CREATE VOLUME](https://docs.databricks.com/en/connect/unity-catalog/create-volume.html)\n",
        "- [Unity Catalog - Volumes Overview](https://docs.databricks.com/en/connect/unity-catalog/volumes.html)\n",
        "- [Upload Files to Volumes](https://docs.databricks.com/en/connect/unity-catalog/volumes.html#upload-files)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 4: Carregar Arquivos CSV nos Volumes\n",
        "\n",
        "### M√©todo 1: Usando Python para Upload de Arquivos\n",
        "\n",
        "Para fazer upload dos arquivos CSV para os volumes, voc√™ tem duas op√ß√µes:\n",
        "\n",
        "1. **Upload via UI do Databricks**: Arraste e solte os arquivos na interface\n",
        "2. **Upload via c√≥digo Python**: Use o c√≥digo abaixo em uma c√©lula Python\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# UPLOAD DE ARQUIVOS CSV PARA OS VOLUMES USANDO DBUTILS\n",
        "# Execute esta c√©lula Python para fazer upload dos arquivos\n",
        "# ============================================================\n",
        "\n",
        "# IMPORTANTE: Ajuste os caminhos abaixo para corresponder ao seu ambiente\n",
        "# Op√ß√£o 1: Se os arquivos est√£o em um reposit√≥rio Git conectado ao Databricks\n",
        "repo_path = \"/Workspace/Repos/your_username/smart_claims_dev/data\"  # Ajuste conforme necess√°rio\n",
        "\n",
        "# Op√ß√£o 2: Se voc√™ fez upload manual para DBFS primeiro\n",
        "dbfs_path = \"dbfs:/FileStore/uploads\"  # Ajuste conforme necess√°rio\n",
        "\n",
        "# Caminhos dos volumes no Unity Catalog\n",
        "volume_paths = {\n",
        "    'claims': '/Volumes/smart_claims_dev/00_landing/claims_volume/claims.csv',\n",
        "    'customers': '/Volumes/smart_claims_dev/00_landing/customers_volume/customers.csv',\n",
        "    'policies': '/Volumes/smart_claims_dev/00_landing/policies_volume/policies.csv'\n",
        "}\n",
        "\n",
        "# M√©todo 1: Se os arquivos est√£o em um reposit√≥rio ou caminho local acess√≠vel\n",
        "try:\n",
        "    # Copiar de reposit√≥rio para volumes\n",
        "    dbutils.fs.cp(f\"{repo_path}/claims.csv\", volume_paths['claims'])\n",
        "    dbutils.fs.cp(f\"{repo_path}/customers.csv\", volume_paths['customers'])\n",
        "    dbutils.fs.cp(f\"{repo_path}/policies.csv\", volume_paths['policies'])\n",
        "    print(\"‚úÖ Arquivos copiados com sucesso do reposit√≥rio para os volumes!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Erro ao copiar do reposit√≥rio: {str(e)}\")\n",
        "    print(\"   Tentando m√©todo alternativo via DBFS...\")\n",
        "    \n",
        "    # M√©todo 2: Se os arquivos est√£o no DBFS\n",
        "    try:\n",
        "        dbutils.fs.cp(f\"{dbfs_path}/claims.csv\", volume_paths['claims'])\n",
        "        dbutils.fs.cp(f\"{dbfs_path}/customers.csv\", volume_paths['customers'])\n",
        "        dbutils.fs.cp(f\"{dbfs_path}/policies.csv\", volume_paths['policies'])\n",
        "        print(\"‚úÖ Arquivos copiados com sucesso do DBFS para os volumes!\")\n",
        "    except Exception as e2:\n",
        "        print(f\"‚ö†Ô∏è Erro ao copiar do DBFS: {str(e2)}\")\n",
        "        print(\"\\nüìù Alternativas:\")\n",
        "        print(\"   1. Fa√ßa upload manual via UI do Databricks (recomendado)\")\n",
        "        print(\"   2. Ajuste os caminhos acima para corresponder ao seu ambiente\")\n",
        "        print(\"   3. Use dbutils.fs.put() para fazer upload direto via c√≥digo\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# UPLOAD VIA DBFS E C√ìPIA PARA VOLUMES\n",
        "# ============================================================\n",
        "\n",
        "# Passo 1: Fazer upload dos arquivos para DBFS (usar UI ou dbutils)\n",
        "# dbutils.fs.put(\"dbfs:/FileStore/uploads/claims.csv\", \"conte√∫do_do_arquivo\")\n",
        "\n",
        "# Passo 2: Copiar de DBFS para os volumes\n",
        "# dbutils.fs.cp(\"dbfs:/FileStore/uploads/claims.csv\", \"/Volumes/smart_claims_dev/00_landing/claims_volume/claims.csv\")\n",
        "# dbutils.fs.cp(\"dbfs:/FileStore/uploads/customers.csv\", \"/Volumes/smart_claims_dev/00_landing/customers_volume/customers.csv\")\n",
        "# dbutils.fs.cp(\"dbfs:/FileStore/uploads/policies.csv\", \"/Volumes/smart_claims_dev/00_landing/policies_volume/policies.csv\")\n",
        "\n",
        "print(\"üìù Descomente e execute os comandos acima ap√≥s fazer upload dos arquivos para DBFS\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 5: Verificar Arquivos nos Volumes\n",
        "\n",
        "Ap√≥s fazer upload dos arquivos, verifique se eles est√£o nos volumes:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listar arquivos no volume de claims\n",
        "print(\"=== Arquivos no volume claims_volume ===\")\n",
        "try:\n",
        "    files = dbutils.fs.ls(\"/Volumes/smart_claims_dev/00_landing/claims_volume/\")\n",
        "    for file in files:\n",
        "        print(f\"  - {file.name} ({file.size} bytes)\")\n",
        "except Exception as e:\n",
        "    print(f\"  ‚ö†Ô∏è Erro ao listar: {str(e)}\")\n",
        "\n",
        "print(\"\\n=== Arquivos no volume customers_volume ===\")\n",
        "try:\n",
        "    files = dbutils.fs.ls(\"/Volumes/smart_claims_dev/00_landing/customers_volume/\")\n",
        "    for file in files:\n",
        "        print(f\"  - {file.name} ({file.size} bytes)\")\n",
        "except Exception as e:\n",
        "    print(f\"  ‚ö†Ô∏è Erro ao listar: {str(e)}\")\n",
        "\n",
        "print(\"\\n=== Arquivos no volume policies_volume ===\")\n",
        "try:\n",
        "    files = dbutils.fs.ls(\"/Volumes/smart_claims_dev/00_landing/policies_volume/\")\n",
        "    for file in files:\n",
        "        print(f\"  - {file.name} ({file.size} bytes)\")\n",
        "except Exception as e:\n",
        "    print(f\"  ‚ö†Ô∏è Erro ao listar: {str(e)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 6: Ler Arquivos dos Volumes como DataFrames (Opcional)\n",
        "\n",
        "Ap√≥s os arquivos estarem nos volumes, voc√™ pode ler diretamente como DataFrames Spark:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ler arquivos CSV dos volumes como DataFrames Spark\n",
        "# Descomente ap√≥s fazer upload dos arquivos\n",
        "\n",
        "# df_claims = spark.read \\\n",
        "#     .option(\"header\", \"true\") \\\n",
        "#     .option(\"inferSchema\", \"true\") \\\n",
        "#     .csv(\"/Volumes/smart_claims_dev/00_landing/claims_volume/claims.csv\")\n",
        "\n",
        "# df_customers = spark.read \\\n",
        "#     .option(\"header\", \"true\") \\\n",
        "#     .option(\"inferSchema\", \"true\") \\\n",
        "#     .csv(\"/Volumes/smart_claims_dev/00_landing/customers_volume/customers.csv\")\n",
        "\n",
        "# df_policies = spark.read \\\n",
        "#     .option(\"header\", \"true\") \\\n",
        "#     .option(\"inferSchema\", \"true\") \\\n",
        "#     .csv(\"/Volumes/smart_claims_dev/00_landing/policies_volume/policies.csv\")\n",
        "\n",
        "# Mostrar preview dos dados\n",
        "# print(\"=== Preview: Claims ===\")\n",
        "# df_claims.show(5, truncate=False)\n",
        "# print(f\"\\nTotal de registros: {df_claims.count()}\")\n",
        "\n",
        "# print(\"\\n=== Preview: Customers ===\")\n",
        "# df_customers.show(5, truncate=False)\n",
        "# print(f\"\\nTotal de registros: {df_customers.count()}\")\n",
        "\n",
        "# print(\"\\n=== Preview: Policies ===\")\n",
        "# df_policies.show(5, truncate=False)\n",
        "# print(f\"\\nTotal de registros: {df_policies.count()}\")\n",
        "\n",
        "print(\"üìù Descomente o c√≥digo acima ap√≥s fazer upload dos arquivos para os volumes\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
